{
 "metadata": {
  "name": "",
  "signature": "sha256:260eb50086000018249b161243bad76f8948ea91cc1914becc77d8427f8b56c6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline \n",
      "\n",
      "import matplotlib as mlp\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from operator import itemgetter\n",
      "import os\n",
      "import pandas as pd\n",
      "from scipy.stats import randint as sp_randint\n",
      "import sklearn\n",
      "from sklearn import cross_validation\n",
      "from sklearn import datasets\n",
      "from sklearn import ensemble\n",
      "from sklearn import grid_search\n",
      "from sklearn import metrics\n",
      "from sklearn import preprocessing\n",
      "import time\n",
      "\n",
      "plt.style.use('fivethirtyeight')\n",
      "\n",
      "_DATA_DIR = 'data'\n",
      "_DATA_PATH = os.path.join(_DATA_DIR, 'titanic.csv')\n",
      "\n",
      "# To encode categorical variables\n",
      "label_encoder = preprocessing.LabelEncoder()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(_DATA_PATH)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Preprocessing Variables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del df['row.names']\n",
      "df['pclass'] = label_encoder.fit_transform(df.pclass)\n",
      "df['embarked'] = label_encoder.fit_transform(df.embarked)\n",
      "df['sex'] = label_encoder.fit_transform(df.sex)\n",
      "def convert_age(number):\n",
      "    try:\n",
      "        number = int(number)\n",
      "    except ValueError:\n",
      "        number = 0\n",
      "    return number\n",
      "\n",
      "def extract_home_destination(address):\n",
      "    try:\n",
      "        address = address.split(',')[-1]\n",
      "    except AttributeError:\n",
      "        address = ''\n",
      "    return address\n",
      "\n",
      "df.age = df.age.apply(convert_age)\n",
      "# Preprocess first\n",
      "df['home.dest'] = df['home.dest'].apply(extract_home_destination)\n",
      "df['destination'] = label_encoder.fit_transform(df['home.dest'])\n",
      "del df['home.dest']\n",
      "del df['boat']\n",
      "del df['ticket']\n",
      "del df['name']\n",
      "del df['room']\n",
      "y = np.array(df.survived.tolist())\n",
      "del df['survived']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = ['pclass', 'age', 'embarked', 'sex', 'destination']\n",
      "X = df[feature_names].as_matrix()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "param_grid = {\n",
      "              'learning_rate': [0.1, 0.05, 0.01],\n",
      "              'max_depth': [4, 6],\n",
      "              'min_samples_leaf': [1, 2, 3, 4, 9, 15],\n",
      "              'n_estimators': [1000, 2000, 3000],\n",
      "              }\n",
      "\n",
      "est = ensemble.GradientBoostingClassifier()\n",
      "\n",
      "start_time = time.time()\n",
      "# run randomized search\n",
      "n_iter_search = 20\n",
      "randomized_search = grid_search.RandomizedSearchCV(est, param_distributions=param_grid,\n",
      "    n_iter=n_iter_search, n_jobs=4).fit(X_train, y_train)\n",
      "\n",
      "gs_cv = grid_search.GridSearchCV(est, param_grid, n_jobs=4).fit(X_train, y_train)\n",
      "end_time = time.time()\n",
      "\n",
      "print('It took {} seconds'.format(end_time - start_time))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "It took 854.242712975 seconds\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# best hyperparameter setting\n",
      "randomized_search.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "{'learning_rate': 0.01,\n",
        " 'max_depth': 6,\n",
        " 'min_samples_leaf': 1,\n",
        " 'n_estimators': 3000}"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "randomized_search.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "0.80000000000000004"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "randomized_search.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "[mean: 0.78095, std: 0.01720, params: {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.79143, std: 0.00841, params: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 2},\n",
        " mean: 0.77810, std: 0.00750, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 4},\n",
        " mean: 0.78000, std: 0.01761, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.77810, std: 0.02117, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.78762, std: 0.01984, params: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.77810, std: 0.00750, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 4},\n",
        " mean: 0.79048, std: 0.00971, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.78571, std: 0.01910, params: {'n_estimators': 2000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.79429, std: 0.00808, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 15},\n",
        " mean: 0.78476, std: 0.01102, params: {'n_estimators': 2000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 4},\n",
        " mean: 0.78286, std: 0.00841, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 2},\n",
        " mean: 0.78667, std: 0.00486, params: {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 2},\n",
        " mean: 0.78762, std: 0.01482, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 15},\n",
        " mean: 0.78476, std: 0.01751, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.79619, std: 0.00539, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 15},\n",
        " mean: 0.80000, std: 0.00700, params: {'n_estimators': 3000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 1},\n",
        " mean: 0.79810, std: 0.01151, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 1},\n",
        " mean: 0.79905, std: 0.01406, params: {'n_estimators': 3000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 1},\n",
        " mean: 0.78667, std: 0.00486, params: {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 2}]"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Comparison between Grid Search and Randomized Parameter Search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = ensemble.RandomForestClassifier()\n",
      "\n",
      "def report(grid_scores, n_top=3):\n",
      "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
      "    for ii, score in enumerate(top_scores):\n",
      "        print(\"Model with rank: {}\".format(ii + 1))\n",
      "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
      "              score.mean_validation_score,\n",
      "              np.std(score.cv_validation_scores)))\n",
      "        print(\"Parameters: {}\\n\".format(score.parameters))\n",
      "\n",
      "param_grid = {\"max_depth\": [3, 2, 1, None],\n",
      "              \"max_features\": [1, 2, 3, 4],\n",
      "              \"min_samples_split\": [1, 2, 3, 4],\n",
      "              \"min_samples_leaf\": [1, 2, 3, 4],\n",
      "              \"bootstrap\": [True, False],\n",
      "              \"criterion\": [\"gini\", \"entropy\"],\n",
      "              'n_estimators': [50, 100, 1000, 2000, 3000],\n",
      "}\n",
      "\n",
      "n_iter_search = 20\n",
      "random_search = grid_search.RandomizedSearchCV(clf, param_distributions=param_dist,\n",
      "                                   n_iter=n_iter_search)\n",
      "\n",
      "start = time.time()\n",
      "random_search.fit(X, y)\n",
      "end = time.time()\n",
      "print(\"RandomizedSearchCV took {0:.2f} seconds for {} candidates\"\n",
      "      \" parameter settings.\".format((end - start), n_iter_search))\n",
      "report(random_search.grid_scores_)\n",
      "\n",
      "\n",
      "param_grid = {\"max_depth\": [3, 2, 1, None],\n",
      "              \"max_features\": [1, 2, 3, 4],\n",
      "              \"min_samples_split\": [1, 2, 3, 4],\n",
      "              \"min_samples_leaf\": [1, 2, 3, 4],\n",
      "              \"bootstrap\": [True, False],\n",
      "              \"criterion\": [\"gini\", \"entropy\"],\n",
      "              'n_estimators': [50, 100, 1000, 2000, 3000],\n",
      "}\n",
      "\n",
      "gs = grid_search.GridSearchCV(clf, param_grid=param_grid)\n",
      "start = time.time()\n",
      "gs.fit(X, y)\n",
      "end = time.time()\n",
      "\n",
      "print(\"GridSearchCV took {0:.2f} seconds for {} candidate parameter settings.\".format(\n",
      "      (end - start, len(gs.grid_scores_))))\n",
      "report(gs.grid_scores_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}